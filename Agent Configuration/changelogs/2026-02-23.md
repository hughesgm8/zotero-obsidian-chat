# Changelog â€” 2026-02-23

## [Session 3] Fix: surface MCP tool errors in chat instead of passing to LLM

- **File Modified**: `src/mcp-client.ts`
- **Change**: `callTool()` now checks the `isError` flag on the MCP tool response. If the server signals a tool error, the method throws immediately rather than returning the error text as if it were valid results.
- **Logic Update**:
  ```
  BEFORE:
    result = send("tools/call", ...) as { content? }
    return result.content.filter(text).join("\n")
    // error text silently returned as "search results"

  AFTER:
    result = send("tools/call", ...) as { content?, isError? }
    text = result.content.filter(text).join("\n")
    if (result.isError) throw new Error(`Zotero search failed: ${text}`)
    return text
    // error is thrown â†’ handleSend() catch block displays it in chat
  ```
- **Reason**: When zotero-mcp returns a tool error (e.g. "Collection [zotero_library] already exists" â€” a ChromaDB state error), the plugin was passing the error text to the LLM as "context." The LLM would then produce a confused response implying the paper wasn't in the library. Now the error surfaces directly in the chat as "Error: Zotero search failed: ..." so the user knows to restart the server rather than doubting their library.

---

## [Session 2] Save conversations + attach active note

- **File Modified**: `src/types.ts`
- **Change**: Added `saveFolder: string` to `ZoteroMCPSettings` (default: `"Zotero Chats"`).
- **Reason**: New setting controls where saved conversation files are written in the vault.

---

- **File Modified**: `src/settings.ts`
- **Change**: Added "Save conversations to" text field in the Behavior section. Defaults to `"Zotero Chats"`. Guards against empty input by falling back to the default.
- **Reason**: Lets users choose a custom vault folder for saved chats without touching code.

---

- **File Modified**: `src/chat-view.ts`
- **Change**: Four additions â€” (1) Save button (floppy disk icon) added to the chat header alongside the clear button; (2) Paperclip button added to the left of the input area; (3) Attachment chip displayed above the input row showing the attached note name with a dismiss Ã—; (4) Two new private state fields: `attachedNote` and `attachmentChipEl`.
- **Logic Update**:
  ```
  saveConversation():
    If no user messages â†’ Notice "Nothing to save yet"
    Build path: {saveFolder}/YYYY-MM-DD/HH-MM-SS - {first 40 chars of first message}.md
    Create root folder + date subfolder if missing (vault.getAbstractFileByPath â†’ createFolder)
    Build markdown: YAML frontmatter, title, each message with sources + ðŸ“Ž annotation
    vault.create(fullPath, content) â†’ Notice "Saved to {path}"

  attachActiveNote():
    Get active file via workspace.getActiveFile()
    If null â†’ Notice "No note is currently open"
    Read content via vault.read(), truncate to fullTextMaxChars
    Set attachedNote = { name, path, content } â†’ renderAttachmentChip()

  handleSend() (modified):
    If attachedNote set â†’ prepend note content to orchestrator question
    Store only rawQuestion in ChatMessage (display-only; note content not shown in chat)
    Store attachedNotePath on message for the save feature
    Attachment persists across sends; user removes it with Ã—
  ```
- **Reason**: Two features requested by user â€” (1) save conversations as vault notes in date-organized folders; (2) attach the currently open note as context so the LLM can answer questions about what you're writing without manual copy-paste.

---

- **File Modified**: `styles.css`
- **Change**: Added `.zotero-chat-header-actions` wrapper to group save + clear buttons. Changed `.zotero-chat-input-area` from a single flex row to a column, with a new `.zotero-chat-input-row` inner row. Added styles for `.zotero-chat-paperclip-btn`, `.zotero-chat-attachment-chip-area`, `.zotero-chat-attachment-chip`, and `.zotero-chat-attachment-remove`.
- **Reason**: Layout changes needed to accommodate the attachment chip above the input row and the paperclip button to the left of the textarea.

---

## [17:45] Add full text retrieval to query pipeline

- **File Modified**: `src/types.ts`
- **Change**: Added two new settings: `fullTextTopN` (default 3) and `fullTextMaxChars` (default 4000). These control how many of the top search results get full paper text fetched, and how much text per paper.
- **Reason**: The orchestrator was only sending metadata (title, authors, abstract) to the LLM. Without full text, the AI couldn't reference actual paper content and would ask the user to "confirm access to full texts."

---

- **File Modified**: `src/orchestrator.ts`
- **Change**: Added a new step between metadata fetch and context building. For the top N results (configurable), calls `zotero_get_item_fulltext` to retrieve the paper body, truncates to the configured max, and includes it in the context sent to the LLM. Remaining results still get metadata only.
- **Logic Update**:
  ```
  Pipeline is now:
    1) zotero_semantic_search â†’ item keys
    2) zotero_get_item_metadata for each key
    3) zotero_get_item_fulltext for top N keys (NEW)
    4) Build context: top N get metadata + full text, rest get metadata only
    5) Send context + question + history to LLM
  buildContext() now accepts a fullTexts Map and appends text under each source
  Truncated text is labeled "(truncated)" so the LLM knows it's partial
  ```
- **Reason**: Full paper text is critical for useful research answers. The controls prevent overwhelming local model context windows.

---

- **File Modified**: `src/settings.ts`
- **Change**: Added two new sliders in the Behavior section: "Papers with full text" (0-5, default 3) and "Max text per paper" (1,000-16,000 characters, default 4,000).
- **Reason**: Users need to tune the tradeoff between answer depth and resource usage, especially with local models that have smaller context windows.

---

## [17:30] Fix CORS and SSE â€” switch MCP client to Node http module

- **File Modified**: `src/mcp-client.ts`
- **Change**: Rewrote from browser `fetch` API to Node.js `http` module. The previous `fetch` attempt was blocked by CORS (`app://obsidian.md` origin rejected by local server) and spammed the console with `ERR_CONNECTION_REFUSED` during polling. Node's `http` module runs outside the browser sandbox â€” no CORS, no console noise, and full control over SSE stream reading.
- **Logic Update**:
  ```
  send(): http.request() POST â†’ read response
    If text/event-stream: readSSEFromStream() reads chunks, finds first "data:" line,
      parses JSON-RPC, destroys connection, returns result
    If application/json: read full body, parse, return
  sendNotification(): http.request() fire-and-forget, consume body with res.resume()
  ```
- **Reason**: fetch in Obsidian's Electron renderer is subject to CORS policy. requestUrl bypasses CORS but hangs on SSE streams. Node http does both: no CORS and handles streaming.

---

- **File Modified**: `src/mcp-server.ts`
- **Change**: Switched readiness probe back to `requestUrl` (from `fetch`). The GET probe returns a finite 400 JSON response (not SSE), so requestUrl handles it fine and doesn't trigger CORS errors.
- **Reason**: Same CORS issue â€” fetch was blocked, requestUrl works for non-streaming responses.

---

## [17:10] Fix SSE streaming hang â€” switch MCP client from requestUrl to fetch (reverted)

- **File Modified**: `src/mcp-client.ts`
- **Change**: Rewrote the entire HTTP layer. Replaced Obsidian's `requestUrl` with the browser Fetch API + ReadableStream. The MCP server returns SSE (Server-Sent Events) responses with `connection: keep-alive` â€” `requestUrl` waited for the connection to close, which never happened, causing every request to hang indefinitely. The new implementation reads the SSE stream line-by-line, extracts the JSON-RPC response from the first `data:` event, then aborts the connection.
- **Logic Update**:
  ```
  send():
    Use fetch() with AbortController
    If response is text/event-stream â†’ readSSEResponse()
    If response is application/json â†’ parse directly
  readSSEResponse():
    Read stream via reader.read() in a loop
    Buffer partial lines, process complete lines
    On "data: {json}" line â†’ parse, cancel reader, abort controller, return result
  sendNotification():
    Fire-and-forget via fetch, abort immediately after headers arrive
  ```
- **Reason**: Root cause of the "did not become ready within 30s" error. The server was running fine â€” the client was hanging on the SSE stream.

---

- **File Modified**: `src/mcp-server.ts`
- **Change**: Replaced the readiness probe from a full MCP `initialize` POST (which returned a hanging SSE stream) to a simple GET request. The GET returns a 400 "Missing session ID" instantly, which is enough to prove the server is alive. Also removed the `requestUrl` import (no longer needed).
- **Logic Update**:
  ```
  waitForReady():
    Old: POST initialize request via requestUrl â†’ hung on SSE stream
    New: GET /mcp with Accept headers â†’ 400 response = server is alive
  ```
- **Reason**: Same SSE streaming issue as the client. The readiness probe needs a quick yes/no, not a full protocol handshake.

---

## [17:00] Increase MCP server startup timeout

- **File Modified**: `src/mcp-server.ts`
- **Change**: Increased the readiness timeout from 15 seconds to 30 seconds.
- **Logic Update**:
  ```
  waitForReady(timeoutMs = 15000) â†’ waitForReady(timeoutMs = 30000)
  ```
- **Reason**: The server was starting successfully but the readiness check timed out while zotero-mcp loaded the ChromaDB vector index. 15 seconds wasn't enough on first boot.

---

## [16:45] Fix settings language and MCP server PATH resolution

- **File Modified**: `src/settings.ts`
- **Change**: Rewrote all settings labels and descriptions to use plain language. Renamed "MCP Server" section to "Zotero MCP Server", "LLM Provider" to "AI Model". Moved server port and Ollama address into a collapsed "Advanced" section. Added helpful context to descriptions (e.g., "Must already be downloaded in Ollama", "Get one at openrouter.ai").
- **Logic Update**:
  ```
  Renamed: "zotero-mcp executable path" â†’ "Zotero MCP command"
  Renamed: "Conversation history length" â†’ "Conversation memory"
  Moved to Advanced (collapsed): server port, Ollama base URL
  Provider dropdown now shows: "Ollama (Local, free)", "OpenRouter (cloud, many models)", "Anthropic (Claude)"
  ```
- **Reason**: User feedback â€” the original labels assumed developer knowledge (executable, binary, PATH, port). Plugin should be usable by researchers, not just developers.

---

- **File Modified**: `src/mcp-server.ts`
- **Change**: Added `getShellPATH()` function that reads the user's full shell PATH before spawning `zotero-mcp`. macOS GUI apps like Obsidian don't inherit shell PATH, so tools installed via pip/Homebrew/pyenv weren't being found. Also improved error messages: ENOENT now says "Could not find zotero-mcp" instead of a cryptic Node.js error.
- **Logic Update**:
  ```
  getShellPATH():
    Try: run "zsh -ilc 'echo $PATH'" to get user's real PATH
    Fallback: manually include /usr/local/bin, /opt/homebrew/bin, Python framework dirs, ~/.local/bin, ~/.pyenv/shims
    Merge with existing process.env.PATH
  spawn() now passes env: { ...process.env, PATH: getShellPATH() }
  Added lastError field + getLastError() for clearer error reporting
  ```
- **Reason**: zotero-mcp lives at `/Library/Frameworks/Python.framework/Versions/3.12/bin/zotero-mcp` which Obsidian's default PATH doesn't include. This was causing "Plugin not ready" errors.

---

- **File Modified**: `src/main.ts`
- **Change**: Improved the error notice when MCP server fails to start â€” now shows the actual error message and stays visible for 10 seconds instead of the default brief flash.
- **Reason**: User needs to see what went wrong, not just that something failed.

---

## [14:10] Full plugin implementation from approved plan

- **File Modified**: `manifest.json` (new)
- **Change**: Created Obsidian plugin manifest â€” ID `zotero-mcp-chat`, desktop only, min version 0.15.0
- **Reason**: Required for Obsidian to recognize and load the plugin

---

- **File Modified**: `package.json` (new)
- **Change**: Created package config with ESM module type, esbuild + TypeScript dev dependencies
- **Reason**: Build toolchain for bundling TypeScript into the single `main.js` Obsidian expects

---

- **File Modified**: `tsconfig.json` (new)
- **Change**: Strict TypeScript config targeting ES6 with bundler module resolution
- **Reason**: Type safety for the plugin codebase

---

- **File Modified**: `esbuild.config.mjs` (new)
- **Change**: Build script that bundles `src/main.ts` â†’ `main.js` (CJS format), externalizes obsidian/electron/codemirror
- **Logic Update**:
  ```
  entryPoints: src/main.ts â†’ main.js
  format: CJS (Obsidian requirement)
  external: obsidian, electron, codemirror, node builtins
  watch mode for dev, single build for production
  ```
- **Reason**: Obsidian plugins must be a single CJS file with obsidian as an external

---

- **File Modified**: `versions.json` (new)
- **Change**: Maps plugin version 0.1.0 to minimum Obsidian version 0.15.0
- **Reason**: Required by Obsidian plugin spec

---

- **File Modified**: `src/types.ts` (new)
- **Change**: Defined `ZoteroMCPSettings` interface with MCP server, LLM provider (Ollama/OpenRouter/Anthropic), and behavior settings. Includes `DEFAULT_SETTINGS`, `ChatMessage`, and `ZoteroSource` types.
- **Logic Update**:
  ```
  ZoteroMCPSettings: mcpExecutablePath, mcpServerPort, llmProvider, per-provider configs
  Defaults: Ollama at localhost:11434, deepseek-r1:8b, port 8000
  ChatMessage: role, content, sources[], timestamp
  ZoteroSource: key, title, authors, year, itemType, abstract
  ```
- **Reason**: Central type definitions shared across all modules

---

- **File Modified**: `src/settings.ts` (new)
- **Change**: Settings tab with 3 sections: MCP Server (path, port), LLM Provider (dropdown that re-renders to show/hide provider-specific fields), Behavior (history length slider, system prompt)
- **Reason**: Users need to configure the MCP executable path, choose their LLM provider, and enter API keys

---

- **File Modified**: `src/mcp-server.ts` (new)
- **Change**: `MCPServerManager` class that spawns `zotero-mcp serve --transport streamable-http --port <port>` as a child process, polls the HTTP endpoint until ready (15s timeout), and kills the process on stop
- **Logic Update**:
  ```
  start(): spawn child process â†’ poll /mcp with initialize request â†’ return when ready
  stop(): SIGTERM the child process
  isRunning(): check process is alive
  stderr captured for error reporting (last 50 lines)
  ```
- **Reason**: Auto-manages the MCP server lifecycle so users don't need to start it manually

---

- **File Modified**: `src/mcp-client.ts` (new)
- **Change**: Minimal MCP client implementing JSON-RPC 2.0 over HTTP using Obsidian's `requestUrl`. Handles initialize handshake, session ID tracking, SSE response parsing, tool calls.
- **Logic Update**:
  ```
  initialize(): send initialize â†’ send notifications/initialized
  callTool(name, args): JSON-RPC tools/call â†’ parse text content from response
  Tracks Mcp-Session-Id header across requests
  Handles both JSON and SSE (text/event-stream) responses
  ```
- **Reason**: Custom implementation instead of MCP SDK because the SDK's Node HTTP deps don't work in Obsidian's Electron renderer. The protocol is simple JSON-RPC POSTs.

---

- **File Modified**: `src/llm/llm-provider.ts` (new)
- **Change**: `LLMProvider` interface with `chat(messages)`, `testConnection()`, `getModelName()`
- **Reason**: Abstraction layer so the orchestrator doesn't care which LLM is behind it

---

- **File Modified**: `src/llm/ollama.ts` (new)
- **Change**: Ollama provider using OpenAI-compatible `/v1/chat/completions` endpoint, connection test via `/api/tags`
- **Reason**: Primary provider â€” free, local, no API key needed

---

- **File Modified**: `src/llm/openrouter.ts` (new)
- **Change**: OpenRouter provider using same chat completions format with Bearer auth and referer headers
- **Reason**: Access to many models with a single API key

---

- **File Modified**: `src/llm/anthropic.ts` (new)
- **Change**: Anthropic provider using Messages API with system prompt in top-level field (not in messages array)
- **Reason**: Claude API has a different format from OpenAI-compatible endpoints

---

- **File Modified**: `src/llm/index.ts` (new)
- **Change**: Factory function `createLLMProvider(settings)` that returns the correct provider instance based on settings
- **Reason**: Single entry point for provider creation

---

- **File Modified**: `src/orchestrator.ts` (new)
- **Change**: Deterministic pipeline: (1) `zotero_semantic_search` with user question, (2) extract item keys, (3) `zotero_get_item_metadata` for each, (4) build context string, (5) send to LLM with conversation history (truncated to configurable limit)
- **Logic Update**:
  ```
  query(question, history):
    searchResult = mcpClient.callTool("zotero_semantic_search", {query})
    keys = extractItemKeys(searchResult)  // JSON parse or regex fallback
    sources = for each key: callTool("zotero_get_item_metadata", {item_key})
    context = format sources as numbered list with title/authors/year/abstract
    messages = [system prompt] + [recent history] + [context + question]
    return llmProvider.chat(messages)
  ```
- **Reason**: Fixed pipeline is more reliable than letting local models choose tools (per plan)

---

- **File Modified**: `src/chat-view.ts` (new)
- **Change**: `ItemView` subclass for right sidebar. DOM-based UI with: status dot (green/yellow/red), scrollable message list, markdown-rendered assistant responses, source citations below each response, copy button, clear chat button, textarea with Enter-to-send
- **Reason**: The user-facing chat panel, modeled after Obsidian Copilot

---

- **File Modified**: `src/main.ts` (new)
- **Change**: Plugin entry point. On load: loads settings, registers chat view, adds ribbon icon + command, starts MCP server in background. On unload: closes MCP client and kills server process. Re-creates orchestrator when settings change.
- **Reason**: Wires all components together into the Obsidian plugin lifecycle

---

- **File Modified**: `styles.css` (new)
- **Change**: Flexbox layout for chat panel using Obsidian CSS variables (`--background-primary`, `--text-normal`, `--interactive-accent`, etc.) for light/dark theme compatibility. User messages right-aligned with accent color, assistant messages left-aligned with secondary background.
- **Reason**: Match Obsidian's native look and feel
